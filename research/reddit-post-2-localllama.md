TITLE:
Chinese open-source model dump this week: MiniMax M2.5, Ant Group Ring-2.5-1T (trillion-param hybrid architecture), ByteDance Doubao 2.0

BODY:
Big week for Chinese open-source releases. I track 11 Chinese AI sources daily — here's the rundown:

**MiniMax M2.5** — Open-sourced their flagship model. Notable because it was running on Huawei Ascend Atlas hardware within hours of release, suggesting pre-coordinated optimization for domestic chips.

**Ant Group Ring-2.5-1T** — Described as "world's first hybrid linear architecture trillion-parameter reasoning model." Not a standard transformer. The hybrid linear approach is interesting for anyone following alternative architectures.

**ByteDance Doubao 2.0** — Major upgrade to their LLM, integrated with Seedance 2.0 (video gen). Not open-sourced (yet) but ByteDance has been increasingly open with their model releases.

Has anyone gotten hands on MiniMax M2.5 or Ring-2.5-1T yet? Curious about benchmark comparisons and how the hybrid linear architecture performs on reasoning tasks compared to standard transformer approaches.
